{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab3dac0",
   "metadata": {},
   "source": [
    "# Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "210831e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = []\n",
    "reviews_test = []\n",
    "for line in open('full_train.txt','r', encoding=\"utf8\"):\n",
    "    reviews_train.append(line.strip())\n",
    "for test in open('full_test.txt','r', encoding=\"utf8\"):\n",
    "    reviews_test.append(test.strip())  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d597b6f",
   "metadata": {},
   "source": [
    "UTF-8 is one of the most commonly used encodings, and Python often defaults to using it. UTF stands for “Unicode Transformation Format”, and the ‘8’ means that 8-bit values are used in the encoding.\n",
    "\n",
    "The strip() method returns a copy of the string by removing both the leading and the trailing characters (based on the string argument passed).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d297bf26",
   "metadata": {},
   "source": [
    "# Length of the Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50ad4dad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_train))\n",
    "print(len(reviews_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ac896",
   "metadata": {},
   "source": [
    "# Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d06ee85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d272c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_reviews_train = preprocess_reviews(reviews_train)\n",
    "clean_reviews_test = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "72301f45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell highs satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled  at  high a classic line inspector im here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isnt'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_reviews_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9865622",
   "metadata": {},
   "source": [
    "The re.compile() method is used to compile a regular expression pattern provided as a string into a regex pattern object.\n",
    "\n",
    "In the above code we see that after quotes we have [ ] which mean those square barckets hold list of characters in them. ( ) hold specific patterns within them.\n",
    "\n",
    "The .sub() method will replace all those characters with a blank and in the line that follows .sub() will replace all those patterns with a space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf9163f",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25db93c",
   "metadata": {},
   "source": [
    "### 1) Remove Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b1013",
   "metadata": {},
   "source": [
    "Stop words are the very common words like ‘if’, ‘but’, ‘we’, ‘he’, ‘she’, and ‘they’. We can usually remove these words without changing the semantics of a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a4be1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "english_stop_words = stopwords.words('english')\n",
    "len(english_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89148926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(corpus):\n",
    "    remove_stop_words = []\n",
    "    modified = ''\n",
    "    for review in corpus:\n",
    "        modified = ''\n",
    "        words = review.split()\n",
    "        for word in words:\n",
    "            if word not in english_stop_words:\n",
    "                modified = modified + word + \" \"\n",
    "        remove_stop_words.append(modified)\n",
    "    return remove_stop_words    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d59af38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processed = stopwords_removal(clean_reviews_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a884a14",
   "metadata": {},
   "source": [
    "### 2) Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465af699",
   "metadata": {},
   "source": [
    "Normalzation is the process to convert all of the different forms of a given word into one.\n",
    "\n",
    "It can be implemented in 2 ways mainly Stemming and Lemmitization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc982aa9",
   "metadata": {},
   "source": [
    "#### 1) Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d61b58b",
   "metadata": {},
   "source": [
    "Stemmers remove morphological affixes from words, leaving only the word stem. Basically prefixes and suffixes are removed leaving behind the word stem. We will be using the Porter Stemmer and Snowball Stemmer on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ffeff8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "porter = PorterStemmer()\n",
    "snowball =SnowballStemmer('english')\n",
    "\n",
    "def porter_stemmed_reviews(corpus):\n",
    "    porter_final = []\n",
    "    for review in corpus:\n",
    "        words = word_tokenize(review)\n",
    "        modified_porter = ''\n",
    "        for w in words:\n",
    "            porter_stem = porter.stem(w)\n",
    "            modified_porter = modified_porter + porter_stem + \" \"\n",
    "        porter_final.append(modified_porter)    \n",
    "    return porter_final\n",
    "def snowball_stemmed_reviews(corpus):\n",
    "    snowball_final = []\n",
    "    for review in corpus:\n",
    "        words = review.split()\n",
    "        modified_snowball = ''\n",
    "        for w in words:\n",
    "            snowball_stem = snowball.stem(w)\n",
    "            modified_snowball = modified_snowball + snowball_stem + \" \"\n",
    "        snowball_final.append(modified_snowball)\n",
    "    return snowball_final    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62bce199",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_porter = porter_stemmed_reviews(text_processed)\n",
    "stemmed_snowball = snowball_stemmed_reviews(text_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ed2a2",
   "metadata": {},
   "source": [
    "Porter Stemmer removes suffixes from the word to reduce it to its word stem.\n",
    "\n",
    "Snowball Stemmer is a better and an updated version of Porter. It is called as Porter2 algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36bb70d",
   "metadata": {},
   "source": [
    "#### 2) Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1244a",
   "metadata": {},
   "source": [
    "Lemmatization works by identifying the part-of-speech of a given word and then applying more complex rules to transform the word into its true root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "55076417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatized  = WordNetLemmatizer()\n",
    "def lemmatized_reviews(corpus):\n",
    "    final_lemmatized = []\n",
    "    for review in corpus:\n",
    "        words = review.split()\n",
    "        modified_lemmatized = ''\n",
    "        for w in words:\n",
    "            lemmatized_text = lemmatized.lemmatize(w)\n",
    "            modified_lemmatized = modified_lemmatized + lemmatized_text + \" \"\n",
    "        final_lemmatized.append(modified_lemmatized)\n",
    "    return final_lemmatized                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "87590eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_final = lemmatized_reviews(text_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d81143",
   "metadata": {},
   "source": [
    "In contrast to stemming, lemmatization is a lot more powerful. It looks beyond word reduction and considers a language’s full vocabulary to apply a morphological analysis to words, aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma.\n",
    "\n",
    "An inflectional ending is a word part that is added to the end of a base word that changes the number or tense of a base word. A base word can stand alone and has meaning (for example, cat, bench, eat, walk)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a204641",
   "metadata": {},
   "source": [
    "# Vectorization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7fe4a",
   "metadata": {},
   "source": [
    "### Bag of Words Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cce6fc",
   "metadata": {},
   "source": [
    "The basic definition of Vectorization is to represent text in numerical format. Implementation would be creating one large matrix containing one column of all the unique words. Next is to create rows containing sequence of 0's and 1's. 1 if the word in your corpus is present in that respective column of the matrix and a 0 if it is absent. This is One Hot Encoding.\n",
    "\n",
    "Bag of Words is used to turn text files into numerical vectors or a bag of words.\n",
    "The Bag of Words (BoW) model is the most basic type of numerical text representation. A phrase can be represented as a bag of words vector, just like the term itself (a string of numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "829a86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(binary = True)\n",
    "cv.fit(text_processed)\n",
    "vector_train = cv.transform(clean_reviews_train)\n",
    "vector_test = cv.transform(clean_reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f02ca4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizerTrain(n_grams=1): (25000, 92688)\n",
      "CountVectorizerTest(n_grams=1): (25000, 92688)\n"
     ]
    }
   ],
   "source": [
    "print('CountVectorizerTrain(n_grams=1):',vector_train.shape)\n",
    "print('CountVectorizerTest(n_grams=1):',vector_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffa3bbd",
   "metadata": {},
   "source": [
    "In the above code we used only single word features in our model, which we call 1-grams or unigrams. We can potentially add more predictive power to our model by adding two or three word sequences (bigrams or trigrams) as well. For example, if a review had the three word sequence “didn’t love movie” we would only consider these words individually with a unigram-only model and probably not capture that this is actually a negative sentiment because the word ‘love’ by itself is going to be highly correlated with a positive review.\n",
    "\n",
    "We are increasing the words in our matrix to two or three word sequences. The n-grams parameter allows us to use more than one word sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e095ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = CountVectorizer(binary = False, min_df=0,max_df=1,ngram_range=(1,3))\n",
    "cv1.fit(clean_reviews_train)\n",
    "inc_vector_train = cv1.transform(clean_reviews_train)\n",
    "inc_vector_test = cv1.transform(clean_reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b70a2680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizerTrain(n_grams=1-3): (25000, 4373123)\n",
      "CountVectorizerTest(n_grams=1-3): (25000, 4373123)\n"
     ]
    }
   ],
   "source": [
    "print('CountVectorizerTrain(n_grams=1-3):',inc_vector_train.shape)\n",
    "print('CountVectorizerTest(n_grams=1-3):',inc_vector_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b0aeb",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1730f5a",
   "metadata": {},
   "source": [
    "The term tf–idf stands for term frequency–inverse document frequency, it is a mathematical statistic that is planned to reflect how significant a word is to a record in a collection or corpus. The tf–idf esteem builds proportionally to the number of times a word shows up in the document.\n",
    "\n",
    "Term Frequency (tf) - It gives us the recurrence of the word in each report in the corpus. It is the proportion of the number of times the word shows up in a report contrasted with the all-out the number of words in that record. It increments as the quantity of events of that word inside the record increments.\n",
    "\n",
    "Inverse Document Frequency (idf) - It is used to figure the heaviness of uncommon words over all reports in the corpus. The words that happen seldom in the corpus have a high IDF score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6998c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "tv_train_reviews=tv.fit_transform(clean_reviews_train)\n",
    "tv_test_reviews=tv.transform(clean_reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea586a1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (25000, 4373123)\n",
      "Tfidf_test: (25000, 4373123)\n"
     ]
    }
   ],
   "source": [
    "print('Tfidf_train:',tv_train_reviews.shape)\n",
    "print('Tfidf_test:',tv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1f45d",
   "metadata": {},
   "source": [
    "# Building the Classifier using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "77426c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "faa4e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "target= []\n",
    "for i in range(25000):\n",
    "    if i < 12500:\n",
    "        sentiment = 1\n",
    "    else:\n",
    "        sentiment = 0\n",
    "    target.append(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f17471",
   "metadata": {},
   "source": [
    "The targets/labels we use will be the same for training and testing because both datasets are structured the same, where the first 12.5k are positive and the last 12.5k are negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a901875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(inc_vector_train,target,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45991f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01 : 0.50496\n",
      "Accuracy for C=0.05 : 0.50496\n",
      "Accuracy for C=0.25 : 0.50496\n",
      "Accuracy for C=0.5 : 0.50496\n",
      "Accuracy for C=1 : 0.50496\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train,y_train)\n",
    "    predict = lr.predict(X_val)\n",
    "    print(\"Accuracy for C={} : {}\".format(c,accuracy_score(y_val,predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fffcb2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the Test Data is:0.64664\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=1)\n",
    "final_model.fit(inc_vector_train,target)\n",
    "pred = final_model.predict(inc_vector_test)\n",
    "print('Accuracy on the Test Data is:{}'.format(accuracy_score(target,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07757757",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(tv_train_reviews,target,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7bdd0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01 : 0.49376\n",
      "Accuracy for C=0.05 : 0.49376\n",
      "Accuracy for C=0.25 : 0.49376\n",
      "Accuracy for C=0.5 : 0.49376\n",
      "Accuracy for C=1 : 0.49376\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train,y_train)\n",
    "    predict = lr.predict(X_val)\n",
    "    print(\"Accuracy for C={} : {}\".format(c,accuracy_score(y_val,predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1dc443bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the Test Data is:0.71736\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=0.5)\n",
    "final_model.fit(tv_train_reviews,target)\n",
    "pred = final_model.predict(tv_test_reviews)\n",
    "print('Accuracy on the Test Data is:{}'.format(accuracy_score(target,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "846d9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8bb03a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trian,X_val,y_train,y_val = train_test_split(inc_vector_train,target,test_size = 0.25,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7af32b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01 : 0.49168\n",
      "Accuracy for C=0.05 : 0.49168\n",
      "Accuracy for C=0.25 : 0.48736\n",
      "Accuracy for C=0.5 : 0.48736\n",
      "Accuracy for C=1 : 0.48736\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01,0.05,0.25,0.5,1]:\n",
    "    svm = SVC(C=c)\n",
    "    svm.fit(X_train,y_train)\n",
    "    predict = svm.predict(X_val)\n",
    "    print('Accuracy for C={} : {}'.format(c,accuracy_score(y_val,predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d53519c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data is 0.50064\n"
     ]
    }
   ],
   "source": [
    "final_model = SVC(C=0.01)\n",
    "final_model.fit(inc_vector_train,target)\n",
    "pred = final_model.predict(inc_vector_test)\n",
    "print('Accuracy on Test Data is {}'.format(accuracy_score(target,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4c49eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(tv_train_reviews,target,test_size = 0.25,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b1bc11a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01 : 0.49168\n",
      "Accuracy for C=0.05 : 0.49168\n",
      "Accuracy for C=0.25 : 0.49168\n",
      "Accuracy for C=0.5 : 0.49168\n",
      "Accuracy for C=1 : 0.49168\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01,0.05,0.25,0.5,1]:\n",
    "    svm = SVC(C=c)\n",
    "    svm.fit(X_train,y_train)\n",
    "    predict = svm.predict(X_val)\n",
    "    print('Accuracy for C={} : {}'.format(c,accuracy_score(y_val,predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8bb21a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data is 0.50392\n"
     ]
    }
   ],
   "source": [
    "final_model = SVC(C=1)\n",
    "final_model.fit(tv_train_reviews,target)\n",
    "pred = final_model.predict(tv_test_reviews)\n",
    "print('Accuracy on Test Data is {}'.format(accuracy_score(target,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0dd4e8",
   "metadata": {},
   "source": [
    "As we can see we were able to achieve an accuracy of 72% with Logistic Regression and 51% with Support Vector Machines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
